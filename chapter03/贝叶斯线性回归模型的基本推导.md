### 1. 贝叶斯线性回归模型的基本推导

贝叶斯线性回归的目标是根据观察到的数据$$X$$和响应$$t$$，通过贝叶斯推理来推算出线性回归模型的参数（权重$$w$$）和模型的不确定性。

假设线性回归模型为：

$$t = Xw + \epsilon$$

其中：
- $$t$$是$$n \times 1$$的响应向量，
- $$X $$是$$n \times d$$的设计矩阵（每一行是一个数据样本，每一列是一个特征），
- $$w$$是$$d \times 1 $$的回归权重，
- $$\epsilon $$是$$n \times 1$$的噪声向量。

假设噪声$$\epsilon $$服从高斯分布，即：

$$\epsilon \sim \mathcal{N}(0, \beta^{-1} I)$$

这意味着噪声具有均值为零，方差为$$\beta^{-1} $$的正态分布。假设$$w$$也有先验分布：

$$w \sim \mathcal{N}(0, \alpha^{-1} I)$$

这里，$$\alpha$$是权重的精度（即$$\alpha^{-1} $$是权重的方差）。

**贝叶斯推理**的目标是根据观察到的$$X $$和$$t$$更新$$w$$的后验分布。我们使用的公式是 **后验分布**的最大化，这可以通过计算后验概率$$p(w | X, t) $$来进行。

#### 后验分布的推导：

根据贝叶斯定理，我们有：

$$p(w | X, t) \propto p(t | X, w) p(w)$$

其中：
- 似然函数$$ p(t | X, w)$$表示给定权重$$w$$时，数据$$t$$的概率。
- 先验$$ p(w)$$表示权重$$w$$的先验分布。

由于噪声$$ \epsilon$$服从正态分布，所以似然函数可以写为：

$$p(t | X, w) = \mathcal{N}(t | Xw, \beta^{-1} I)$$

而权重的先验分布是：

$$p(w) = \mathcal{N}(w | 0, \alpha^{-1} I)$$

因此，后验分布是：

$$p(w | X, t) \propto \exp \left( -\frac{\beta}{2} (t - Xw)^T (t - Xw) \right) \exp \left( -\frac{\alpha}{2} w^T w \right)$$

结合似然函数和先验分布，得到后验分布：

$$p(w | X, t) \propto \exp \left( -\frac{1}{2} \left[ \beta (t - Xw)^T (t - Xw) + \alpha w^T w \right] \right)$$

这就是贝叶斯线性回归的后验分布。我们要做的是最大化这个后验分布，找到最佳的权重$$w$$。

#### 最大化后验分布：

为了最大化后验分布，我们实际上是在最大化对数似然函数。最大化对数似然即等价于最小化其负对数。

对数似然函数为：

$$\log p(w | X, t) = -\frac{1}{2} \left[ \beta (t - Xw)^T (t - Xw) + \alpha w^T w \right]$$


这就是我们在代码中要最大化的目标函数。接下来我们需要通过迭代来找到最优的$$w$$，即通过 **固定点方法** 进行优化。

### 2. Mackay 固定点方法

Mackay 固定点方法是一种优化方法，旨在通过迭代过程逐步更新 **精度参数**（$$\alpha$$和$$\beta$$）以及模型的后验均值$$m$$。该方法基于最小化负对数似然函数，并使用**梯度下降法**更新参数。

#### 主要公式和步骤：

1. **初始化**：
   - 选择初始值：$$\alpha = 0.02$$，$$\beta = 0.5$$
   - 计算$$X$$和$$t$$的均值：$$xbar = \text{mean}(X)$$，$$tbar = \text{mean}(t)$$
   - 对$$X$$和$$t$$进行中心化：$$X' = X - xbar$$，$$t' = t - tbar$$

2. **计算矩阵和向量**：
   - $$XX = X X^T$$
   - $$Xt = X t^T$$

3. **迭代更新**：
   - 计算矩阵$$A = \beta XX + \alpha I$$，然后进行 Cholesky 分解得到$$U$$。
   - 计算权重$$m = \beta (U^{-1} (U^{-1} Xt))$$。
   - 计算残差平方和$$e = \sum (t - m^T X)^2$$。
   - 更新对数似然$$\text{llh}$$：
     $$\text{llh}(iter) = \frac{1}{2} \left[ d \log(\alpha) + n \log(\beta) - \alpha m^2 - \beta e - \log(\det(A)) - n \log(2 \pi) \right]$$

4. **更新参数$$\alpha$$和$$\beta$$**：
   - 计算$$V = U^{-1}$$
   - 计算$$\text{trS} = \text{sum}(V^2)$$
   - 更新$$\gamma = d - \alpha \cdot \text{trS}$$
   - 更新$$\alpha = \frac{\gamma}{m^2}$$
   - 更新$$\beta = \frac{n - \gamma}{e}$$

5. **最终模型参数**：
   - 计算偏置项$$w_0 = t_{\text{bar}} - m^T x_{\text{bar}}$$

6. **返回模型**：
   - 包含权重$$w$$、偏置$$w_0$$、精度参数$$\alpha$$和$$\beta$$，以及其他参数。

### 1. 问题定义
给定数据集 $$X $$ 和目标响应 $$t$$，线性回归模型的目标是估计权重向量 $$w $$ 和噪声精度 $$\beta $$。假设噪声 $$\epsilon $$ 服从均值为零，方差为 $$\beta^{-1} $$ 的高斯分布。贝叶斯推理的任务是从数据中得到 $$w $$ 和 $$\beta $$ 的后验分布。

### 2. 似然函数
假设模型为：

$$t = Xw + \epsilon$$

其中：
- $$t$$ 是 $$n \times 1 $$ 的目标向量。
- $$X $$ 是 $$n\times d $$ 的设计矩阵（每一行是一个样本，每一列是一个特征）。
- $$w $$ 是 $$d \times 1 $$ 的权重向量。
- $$\epsilon $$ 是噪声项，假设 $$\epsilon \sim \mathcal{N}(0, \beta^{-1} I)$$，即噪声是均值为0，协方差矩阵为 $$\beta^{-1} I $$ 的高斯分布。

给定 $$w $$，似然函数 $$p(t | X, w)$$ 为：

$$p(t | X, w) = \mathcal{N}(t | Xw, \beta^{-1} I)$$

由于噪声是独立的且服从高斯分布，可以写为：

$$p(t | X, w) = \left( \frac{\beta}{2\pi} \right)^{n/2} \exp \left( -\frac{\beta}{2} \| t - Xw \|^2 \right)$$

其中 $$ \| t - Xw \|^2$$ 表示残差的平方和。

### 3. 权重的先验分布
假设权重 $$w $$ 服从一个零均值的高斯分布，精度为 $$\alpha$$，即：


$$p(w) = \mathcal{N}(w | 0, \alpha^{-1} I)$$

因此，先验的概率密度为：

$$p(w) = \left( \frac{\alpha}{2\pi} \right)^{d/2} \exp \left( -\frac{\alpha}{2} w^T w \right)$$

### 4. 后验分布
根据贝叶斯定理，后验分布 $$p(w | X, t) $$ 是似然函数和先验分布的乘积：

$$p(w | X, t) \propto p(t | X, w) p(w)$$

代入似然函数和先验分布的表达式，得到：

$$p(w | X, t) \propto \exp \left( -\frac{\beta}{2} \| t - Xw \|^2 \right) \exp \left( -\frac{\alpha}{2} w^T w \right)$$

这可以展开为：

$$p(w | X, t) \propto \exp \left( -\frac{\beta}{2} \left( t^T t - 2w^T X^T t + w^T X^T X w \right) - \frac{\alpha}{2} w^T w \right)$$

将相似项组合在一起：

$$p(w | X, t) \propto \exp \left( -\frac{\beta}{2} t^T t + \beta w^T X^T t - \frac{\beta}{2} w^T X^T X w - \frac{\alpha}{2} w^T w \right)$$

注意到 $$ \beta $$ 和 $$\alpha $$ 是常数，因此我们可以忽略掉与它们相关的项，最终得到后验分布的形式：

$$p(w | X, t) \propto \exp \left( -\frac{1}{2} w^T \left( \beta X^T X + \alpha I \right) w + w^T \beta X^T t \right)$$

### 5. 后验分布的最大化（优化）
我们需要最大化后验分布，从而得到 $$w $$ 的最优值。这等价于最小化后验的负对数：

$$-\log p(w | X, t) = \frac{1}{2} w^T \left( \beta X^T X + \alpha I \right) w - w^T \beta X^T t$$

通过对 $$w $$ 进行优化，得到最优解：

$$w_{\text{MAP}} = \left( \beta X^T X + \alpha I \right)^{-1} \beta X^T t$$

### 6. 预测和后验分布的计算
贝叶斯线性回归模型的预测是通过已知的权重 $$w $$ 来进行的。在给定一个新的输入 $$X_{\text{new}} $$ 时，预测值 $$ t_{\text{new}} $$ 为：

$$t_{\text{new}} = X_{\text{new}} w_{\text{MAP}}$$

此外，还可以计算后验分布的方差，以量化预测的不确定性。后验分布的方差为：

$$\text{Var}(t_{\text{new}}) = \left( \beta X_{\text{new}}^T X_{\text{new}} + \alpha I \right)^{-1}$$

这样，我们不仅可以得到预测值，还能计算出预测的不确定性。

### 7.更新$\alpha ,\beta$

$$\alpha$$更新为：$$\alpha=\frac{d-trace(Var)}{w_Tw}, \beta=\frac{n-d+trac(Var)}{e}$$

